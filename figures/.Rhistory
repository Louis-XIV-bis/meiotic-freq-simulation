plot(density(annotations$MQ,na.rm=T),main="MQ")
abline(v=lim.MQ, col="red")
prop.MQ=length( which(annotations$MQ >lim.MQ)) / nrow(annotations)
legend("top", c(paste("Filter: MQ >",lim.MQ,sep=""),
paste("Prop. pass filter = ", signif(prop.MQ,3),sep="")),lty=1,col=c("red", "white"))
plot(density(annotations$MQRankSum,na.rm=T),main="MQRankSum")
abline(v=lim.MQRankSum, col="red")
prop.MQRankSum=length( which(annotations$MQRankSum > lim.MQRankSum)) / sum(!is.na(annotations$MQRankSum))
legend("top", c(paste("Filter: MQRankSum >",lim.MQRankSum,sep=""),
paste("Prop. het. SNPs pass filter = ", signif(prop.MQRankSum,3),sep="")),lty=1,col=c("red", "white"))
plot(density(annotations$ReadPosRankSum,na.rm=T),main="ReadPosRankSum")
abline(v=lim.ReadPosRankSum, col="red")
prop.ReadPosRankSum=length( which(annotations$ReadPosRankSum >lim.ReadPosRankSum)) / sum(!is.na(annotations$ReadPosRankSum))
legend("top", c(paste("Filter: ReadPosRankSum >",lim.ReadPosRankSum, "Nb sites heterozyg =",sum(!is.na(annotations$ReadPosRankSum)),sep=""),
paste("Prop. het. SNPs pass filter = ", signif(prop.ReadPosRankSum,3),sep="")),lty=1,col=c("red", "white"))
plot(density(annotations$SOR,na.rm=T),main="SOR")
abline(v=lim.SOR, col="red")
prop.SOR=length( which(annotations$SOR <lim.SOR)) / nrow(annotations)
legend("top", c(paste("Filter: ReadPosRankSum <",lim.SOR,sep=""),
paste("Prop. pass filter = ", signif(prop.SOR,3),sep="")),lty=1,col=c("red", "white"))
dev.off()
lim.SOR = 2
# Calculate the proportion of rows that did not pass each filter
proportions_pass <- annotations %>%
summarize(
pass_QD = mean(QD > lim.QD, na.rm = TRUE),
pass_FS = mean(FS < lim.FS, na.rm = TRUE),
pass_MQ = mean(MQ > lim.MQ, na.rm = TRUE),
pass_MQRankSum = mean(MQRankSum > lim.MQRankSum, na.rm = TRUE),
pass_ReadPosRankSum = mean(ReadPosRankSum > lim.ReadPosRankSum, na.rm = TRUE),
pass_SOR = mean(SOR < lim.SOR, na.rm = TRUE)
)
print(proportions_pass)
lim.SOR = 2.5
# Calculate the proportion of rows that did not pass each filter
proportions_pass <- annotations %>%
summarize(
pass_QD = mean(QD > lim.QD, na.rm = TRUE),
pass_FS = mean(FS < lim.FS, na.rm = TRUE),
pass_MQ = mean(MQ > lim.MQ, na.rm = TRUE),
pass_MQRankSum = mean(MQRankSum > lim.MQRankSum, na.rm = TRUE),
pass_ReadPosRankSum = mean(ReadPosRankSum > lim.ReadPosRankSum, na.rm = TRUE),
pass_SOR = mean(SOR < lim.SOR, na.rm = TRUE)
)
print(proportions_pass)
min(filtered_data$MQRankSum)
lim.ReadPosRankSum = -5.0
lim.SOR = 2.5
# Calculate the proportion of rows that did not pass each filter
proportions_pass <- annotations %>%
summarize(
pass_QD = mean(QD > lim.QD, na.rm = TRUE),
pass_FS = mean(FS < lim.FS, na.rm = TRUE),
pass_MQ = mean(MQ > lim.MQ, na.rm = TRUE),
pass_MQRankSum = mean(MQRankSum > lim.MQRankSum, na.rm = TRUE),
pass_ReadPosRankSum = mean(ReadPosRankSum > lim.ReadPosRankSum, na.rm = TRUE),
pass_SOR = mean(SOR < lim.SOR, na.rm = TRUE)
)
print(proportions_pass)
lim.ReadPosRankSum = 5.0
lim.SOR = 2.5
# Calculate the proportion of rows that did not pass each filter
proportions_pass <- annotations %>%
summarize(
pass_QD = mean(QD > lim.QD, na.rm = TRUE),
pass_FS = mean(FS < lim.FS, na.rm = TRUE),
pass_MQ = mean(MQ > lim.MQ, na.rm = TRUE),
pass_MQRankSum = mean(MQRankSum < lim.MQRankSum, na.rm = TRUE),
pass_ReadPosRankSum = mean(ReadPosRankSum > lim.ReadPosRankSum, na.rm = TRUE),
pass_SOR = mean(SOR < lim.SOR, na.rm = TRUE)
)
print(proportions_pass)
# Calculate the proportion of rows that did not pass each filter
proportions_pass <- annotations %>%
summarize(
pass_QD = mean(QD > lim.QD, na.rm = TRUE),
pass_FS = mean(FS < lim.FS, na.rm = TRUE),
pass_MQ = mean(MQ > lim.MQ, na.rm = TRUE),
pass_MQRankSum = mean(MQRankSum > lim.MQRankSum, na.rm = TRUE),
pass_ReadPosRankSum = mean(ReadPosRankSum < lim.ReadPosRankSum, na.rm = TRUE),
pass_SOR = mean(SOR < lim.SOR, na.rm = TRUE)
)
print(proportions_pass)
min(filtered_data$MQRankSum)
# Chosed threshold
lim.QD = 8
lim.FS = 60
lim.MQ = 50
lim.MQRankSum = -10
lim.ReadPosRankSum = 5.0
lim.SOR = 2.5
# Calculate the proportion of rows that did not pass each filter
proportions_pass <- annotations %>%
summarize(
pass_QD = mean(QD > lim.QD, na.rm = TRUE),
pass_FS = mean(FS < lim.FS, na.rm = TRUE),
pass_MQ = mean(MQ > lim.MQ, na.rm = TRUE),
pass_MQRankSum = mean(MQRankSum > lim.MQRankSum, na.rm = TRUE),
pass_ReadPosRankSum = mean(ReadPosRankSum < lim.ReadPosRankSum, na.rm = TRUE),
pass_SOR = mean(SOR < lim.SOR, na.rm = TRUE)
)
print(proportions_pass)
# Filter the data
filtered_data <- annotations %>%
filter(
QD > lim.QD,
FS < lim.FS,
MQ > lim.MQ,
MQRankSum > lim.MQRankSum,
ReadPosRankSum > lim.ReadPosRankSum,
SOR < lim.SOR
)
filtered_data
# Calculate the proportion of rows that did not pass each filter
proportions_pass <- annotations %>%
summarize(
pass_QD = mean(QD > lim.QD, na.rm = TRUE),
pass_FS = mean(FS < lim.FS, na.rm = TRUE),
pass_MQ = mean(MQ > lim.MQ, na.rm = TRUE),
pass_MQRankSum = mean(MQRankSum > lim.MQRankSum, na.rm = TRUE),
pass_ReadPosRankSum = mean(ReadPosRankSum < lim.ReadPosRankSum, na.rm = TRUE),
pass_SOR = mean(SOR < lim.SOR, na.rm = TRUE)
)
print(proportions_pass)
# Filter the data
filtered_data <- annotations %>%
filter(
QD > lim.QD,
FS < lim.FS,
MQ > lim.MQ,
MQRankSum > lim.MQRankSum,
ReadPosRankSum < lim.ReadPosRankSum,
SOR < lim.SOR
)
filtered_data
# Filter the data
filtered_data <- annotations %>%
filter(
QD > lim.QD,
FS < lim.FS,
MQ > lim.MQ,
MQRankSum > lim.MQRankSum,
ReadPosRankSum < lim.ReadPosRankSum,
ReadPosRankSum > -lim.ReadPosRankSum,
SOR < lim.SOR
)
View(filtered_data)
filtered_data
cat("Number of rows before filtering:", rows_after, ", after: ", nrow(filtered_data), "\nTotal removed: ", rows_before-nrow(filtered_data))
## DISTRIBUTION
pdf("FiltersDistrib.pdf", width= 12, height = 8)
par(mfrow=c(2,3))
plot(density(annotations$QD,na.rm=T),main=paste("QD , number of SNPs pre-filter = ",nrow(annotations),sep="") )
abline(v=lim.QD, col="red")
prop.QD=length( which(annotations$QD >lim.QD)) / nrow(annotations)
legend("top", c(paste("Filter: QD > ",lim.QD,sep=""),
paste("Prop. pass filter = ", signif(prop.QD,3),sep="")),lty=1,col=c("red", "white"))
## DISTRIBUTION
pdf("FiltersDistrib.pdf", width= 12, height = 8)
par(mfrow=c(2,3))
plot(density(annotations$QD,na.rm=T),main=paste("QD , number of SNPs pre-filter = ",nrow(annotations),sep="") )
abline(v=lim.QD, col="red")
prop.QD=length( which(annotations$QD >lim.QD)) / nrow(annotations)
legend("top", c(paste("Filter: QD > ",lim.QD,sep=""),
paste("Prop. pass filter = ", signif(prop.QD,3),sep="")),lty=1,col=c("red", "white"))
plot(density(annotations$FS,na.rm=T),main="FS")
abline(v=lim.FS, col="red")
prop.FS=length( which(annotations$FS <lim.FS)) / nrow(annotations)
legend("top", c(paste("Filter: FS < ",lim.FS,sep=""),
paste("Prop. pass filter = ", signif(prop.FS,3),sep="")),lty=1,col=c("red", "white"))
plot(density(annotations$MQ,na.rm=T),main="MQ")
abline(v=lim.MQ, col="red")
prop.MQ=length( which(annotations$MQ >lim.MQ)) / nrow(annotations)
legend("top", c(paste("Filter: MQ > ",lim.MQ,sep=""),
paste("Prop. pass filter = ", signif(prop.MQ,3),sep="")),lty=1,col=c("red", "white"))
plot(density(annotations$MQRankSum,na.rm=T),main="MQRankSum")
abline(v=lim.MQRankSum, col="red")
prop.MQRankSum=length( which(annotations$MQRankSum > lim.MQRankSum)) / sum(!is.na(annotations$MQRankSum))
legend("top", c(paste("Filter: MQRankSum > ",lim.MQRankSum,sep=""),
paste("Prop. het. SNPs pass filter = ", signif(prop.MQRankSum,3),sep="")),lty=1,col=c("red", "white"))
plot(density(annotations$ReadPosRankSum,na.rm=T),main="ReadPosRankSum")
abline(v=lim.ReadPosRankSum, col="red")
prop.ReadPosRankSum=length( which(annotations$ReadPosRankSum >lim.ReadPosRankSum)) / sum(!is.na(annotations$ReadPosRankSum))
legend("top", c(paste("Filter: ReadPosRankSum > ",lim.ReadPosRankSum, "Nb sites heterozyg =",sum(!is.na(annotations$ReadPosRankSum)),sep=""),
paste("Prop. het. SNPs pass filter = ", signif(prop.ReadPosRankSum,3),sep="")),lty=1,col=c("red", "white"))
plot(density(annotations$SOR,na.rm=T),main="SOR")
abline(v=lim.SOR, col="red")
prop.SOR=length( which(annotations$SOR <lim.SOR)) / nrow(annotations)
legend("top", c(paste("Filter: ReadPosRankSum < ",lim.SOR,sep=""),
paste("Prop. pass filter = ", signif(prop.SOR,3),sep="")),lty=1,col=c("red", "white"))
dev.off()
### VENN DIAGRAM, intersect of filters
qd.pass = which(annotations$QD>lim.QD)
fs.pass = which(annotations$FS>lim.FS)
sor.pass = which(annotations$SOR > lim.SOR)
mq.pass = which(annotations$MQ < lim.MQ)
mqrs.pass= which(annotations$MQRankSum < lim.MQRankSum)
rprs.pass= which(annotations$ReadPosRankSum < lim.ReadPosRankSum)
x = venn.diagram(
x=list(qd.pass, mq.pass,sor.pass,mqrs.pass,rprs.pass),
category.names = c("QD" , "MQ", "SOR","MQRanksSum", "ReadPosRankSum"),
fill = c("blue","darkgreen","orange","yellow","red"),
output=TRUE,
filename = "Venn_5params_Filters"
)
x
View(annotations)
lim.ReadPosRankSum = 5.0
lim.SOR = 2.5
# Calculate the proportion of rows that did not pass each filter
proportions_pass <- annotations %>%
summarize(
pass_QD = mean(QD > lim.QD, na.rm = TRUE),
pass_FS = mean(FS < lim.FS, na.rm = TRUE),
pass_MQ = mean(MQ > lim.MQ, na.rm = TRUE),
pass_MQRankSum = mean(MQRankSum > lim.MQRankSum, na.rm = TRUE),
pass_ReadPosRankSum = mean(ReadPosRankSum < lim.ReadPosRankSum, na.rm = TRUE),
pass_SOR = mean(SOR < lim.SOR, na.rm = TRUE)
)
print(proportions_pass)
# Filter the data
filtered_data <- annotations %>%
filter(
QD > lim.QD,
FS < lim.FS,
MQ > lim.MQ,
MQRankSum > lim.MQRankSum,
ReadPosRankSum < lim.ReadPosRankSum,
ReadPosRankSum > -lim.ReadPosRankSum,
SOR < lim.SOR
)
print(max(filtered_data$ReadPosRankSum)
print(max(filtered_data$ReadPosRankSum))
print(max(filtered_data$ReadPosRankSum))
print(min(filtered_data$ReadPosRankSum))
print(min(annotations$ReadPosRankSum))
print(max(annotations$ReadPosRankSum))
library(readr)
library(tibble)
library(dplyr)
library(dunn.test)
rm(list=ls())
# Load full dataset
full_dataset = read_csv('../data/t_pichr2_full_merged.csv') %>%
mutate(alpha = as.factor(1 / GR)) %>%
mutate(t = t - 2000)
# Function to test if the distribution of a variable is Gaussian for each combination of `group_var` and `alpha`
check_normality <- function(data, group_var, test_var) {
# Perform Shapiro-Wilk test for normality for each combination of `group_var` and `alpha`
normality_results <- data %>%
group_by(!!sym(group_var), alpha) %>%
summarize(
shapiro_p_value = shapiro.test(!!sym(test_var))$p.value,  # Shapiro-Wilk test for the specified variable
is_gaussian = ifelse(shapiro.test(!!sym(test_var))$p.value > 0.05, "Yes", "No")  # Normality check
)
# Return the results
return(normality_results)
}
perform_tests <- function(data, group_var, value_var, group_col) {
# Check if the grouping column exists
if (!(group_var %in% names(data))) stop("Group variable not found in data.")
if (!(value_var %in% names(data))) stop("Value variable not found in data.")
# Get unique values of the grouping variable
unique_values <- unique(data[[group_col]])
# Loop through each unique value and perform Kruskal-Wallis test
for (value in unique_values) {
# Filter data for the current grouping value
filtered_data <- data %>% filter(!!sym(group_col) == value)
# Perform Kruskal-Wallis test
test_result <- kruskal.test(as.formula(paste(value_var, "~", group_var)), data = filtered_data)
# Print the results
cat("Results for", group_col, "=", value, ":\n")
print(test_result)
# Check if p-value is less than 0.05
if (test_result$p.value < 0.05) {
cat("There's a significant difference between some groups\n")
# Perform Dunn's test for pairwise comparisons
cat("Dunn's test results:\n")
dunn.test(filtered_data[[value_var]], filtered_data[[group_var]])
} else {
cat("No significant difference between groups\n")
}
cat("\n")
}
}
### pi chr 2 alpha = 0.01 vs alpha == 1 ###
data_fig2 = full_dataset %>%
filter(s == 0.05 & rho == '5e-08' & rho_scaled != 'rho_fixe', h == 0.5 & (alpha == 1 | alpha == 0.01))
data_fig2
data_fig2
setwd("~/Documents/meiotic-freq-simulation")
setwd("~/Documents/meiotic-freq-simulation/figures")
rm(list=ls())
# Load full dataset
full_dataset = read_csv('../data/t_pichr2_full_merged.csv') %>%
mutate(alpha = as.factor(1 / GR)) %>%
mutate(t = t - 2000)
full_dataset
# Function to test if the distribution of a variable is Gaussian for each combination of `group_var` and `alpha`
check_normality <- function(data, group_var, test_var) {
# Perform Shapiro-Wilk test for normality for each combination of `group_var` and `alpha`
normality_results <- data %>%
group_by(!!sym(group_var), alpha) %>%
summarize(
shapiro_p_value = shapiro.test(!!sym(test_var))$p.value,  # Shapiro-Wilk test for the specified variable
is_gaussian = ifelse(shapiro.test(!!sym(test_var))$p.value > 0.05, "Yes", "No")  # Normality check
)
# Return the results
return(normality_results)
}
perform_tests <- function(data, group_var, value_var, group_col) {
# Check if the grouping column exists
if (!(group_var %in% names(data))) stop("Group variable not found in data.")
if (!(value_var %in% names(data))) stop("Value variable not found in data.")
# Get unique values of the grouping variable
unique_values <- unique(data[[group_col]])
# Loop through each unique value and perform Kruskal-Wallis test
for (value in unique_values) {
# Filter data for the current grouping value
filtered_data <- data %>% filter(!!sym(group_col) == value)
# Perform Kruskal-Wallis test
test_result <- kruskal.test(as.formula(paste(value_var, "~", group_var)), data = filtered_data)
# Print the results
cat("Results for", group_col, "=", value, ":\n")
print(test_result)
# Check if p-value is less than 0.05
if (test_result$p.value < 0.05) {
cat("There's a significant difference between some groups\n")
# Perform Dunn's test for pairwise comparisons
cat("Dunn's test results:\n")
dunn.test(filtered_data[[value_var]], filtered_data[[group_var]])
} else {
cat("No significant difference between groups\n")
}
cat("\n")
}
}
### pi chr 2 alpha = 0.01 vs alpha == 1 ###
data_fig2 = full_dataset %>%
filter(s == 0.05 & rho == '5e-08' & rho_scaled != 'rho_fixe', h == 0.5 & (alpha == 1 | alpha == 0.01))
data_fig2
check_normality(data_fig2, "window", "pi")
# non parametric test to be exact because only 1 gaussian
pi_alpha_1 <- data_fig2 %>% filter(alpha == 1) %>% pull(pi)
pi_alpha_0.01 <- data_fig2 %>% filter(alpha == 0.01) %>% pull(pi)
wilcox.test(pi_alpha_1, pi_alpha_0.01)
check_normality(data_fig2, "window", "t")
# non parametric test to be exact
t_alpha_1 <- data_fig2 %>% filter(alpha == 1) %>% pull(t)
t_alpha_0.01 <- data_fig2 %>% filter(alpha == 0.01) %>% pull(t)
wilcox.test(t_alpha_1, t_alpha_0.01)
rm(pi_alpha_1, pi_alpha_0.01, t_alpha_1, t_alpha_0.01, data_fig2)
rm(pi_alpha_1, pi_alpha_0.01, t_alpha_1, t_alpha_0.01, data_fig2)
### Compare pi for a given s for each alpha and the opposite ###
data_s = full_dataset %>%
filter(rho == '5e-08' & rho_scaled != 'rho_fixe', h == 0.5)
check_normality(data_s, "s", "pi")
g
g
# Compare pi for each alpha for a given s
perform_tests(data_s, group_var = "alpha", value_var = "pi", group_col = "s")
# Compare pi for each s for a given alpha
perform_tests(data_s, group_var = "s", value_var = "pi", group_col = "alpha")
### Compare t for a given s for each alpha and the opposite ###
check_normality(data_s, "s", "t")
# Will do kruskal walis and dunn.test because not all of them are gaussian
# Compare t for each alpha for a given s
perform_tests(data_s, group_var = "alpha", value_var = "t", group_col = "s")
# Compare t for each s for a given alpha
perform_tests(data_s, group_var = "s", value_var = "t", group_col = "alpha")
### Compare pi for a given rho for each alpha and the opposite ###
data_rho = full_dataset %>%
filter(s ==  0.05 & rho_scaled != 'rho_fixe', h == 0.5)
check_normality(data_rho, "rho", "pi")
# Compare pi for each alpha for a given rho
perform_tests(data_rho, group_var = "alpha", value_var = "pi", group_col = "rho")
# Compare pi for each rho for a given alpha
perform_tests(data_rho, group_var = "rho", value_var = "pi", group_col = "alpha")
### Compare t for a given rho for each alpha and the opposite ###
check_normality(data_rho, "rho", "t")
# Will do kruskal walis and dunn.test because not all of them are gaussian
# Compare t for each alpha for a given rho
perform_tests(data_rho, group_var = "alpha", value_var = "t", group_col = "rho")
# Compare t for each rho for a given alpha
perform_tests(data_rho, group_var = "rho", value_var = "t", group_col = "alpha")
setwd("~/Documents/meiotic-freq-simulation/figures")
library(ggplot2)
library(readr)
library(tibble)
library(dplyr)
library(sjPlot)
library(RColorBrewer)
library(cowplot)
rm(list=ls())
# Subset data for chr1
data_chr1 = read_csv('../data/pi_merged.csv') %>%
filter((h == 0.5 & s == 0.05) & (rho == '5e-08' | rho == '0,00000005')) %>%
mutate(alpha = as.factor(1 / GR)) %>%
mutate(ymin = mean - sd, ymax = mean + sd) %>%
filter(window != 'chr2') %>%
mutate(window = as.numeric(window) / 1000000)
data_chr1
# Subset data for chr2
data_chr2 = read_csv('../data/pi_merged.csv') %>%
filter(window == 'chr2') %>%
filter((h == 0.5 & s == 0.05) & (rho == '5e-08' | rho == '0,00000005')) %>%
mutate(alpha = as.factor(1 / GR)) %>%
mutate(ymin = mean - sd, ymax = mean + sd) %>%
mutate(label = case_when(rho == '5e-08' ~ 'rho', rho == '0,00000005' ~ 'rho_m', TRUE ~ 'other'))
data_chr2
# Explicitly set the y-axis limits to be the same for both plots
y_axis_limits <- c(-1e-5, 8e-05)
# Create color palette
num_conditions <- length(unique(data_chr1$alpha))
palette_name <- "Dark2"
colors <- brewer.pal(n = num_conditions, name = palette_name)
# Using the extracted color palette for both geom_line and geom_ribbon
plot_ctrl_chr1 = data_chr1 %>%
filter(rho == '5e-08') %>%
ggplot(aes(x = window, y = mean, group = alpha)) +
geom_ribbon(aes(ymin = ymin, ymax = ymax, fill = alpha), alpha = 0.2) +
geom_line(aes(color = alpha)) +
scale_color_manual(values = colors) +
scale_fill_manual(values = colors) +
labs(x = "Sequence position (Mbp)",
y = expression(pi ~ "along chromosome 1")) +
theme_light() +
ggtitle(expression(rho ~ "= 5.10-8")) +
theme(
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
axis.text.x = element_text(size = 17),
axis.text.y = element_text(size = 18),
plot.title = element_text(size = 20, hjust = 0.5)
) +
guides(color = "none", fill = "none") +
scale_y_continuous(limits = y_axis_limits)
plot_ctrl_chr1
plot_rhom_chr1 = data_chr1 %>%
filter(rho == '0,00000005') %>%
ggplot(aes(x = window, y = mean, group = alpha)) +
geom_ribbon(aes(ymin = ymin, ymax = ymax, fill = alpha), alpha = 0.2) +
geom_line(aes(color = alpha)) +
scale_color_manual(values = colors) +
scale_fill_manual(values = colors) +
labs(x = "Sequence position (Mbp)",
color = expression(alpha),
fill = expression(alpha),
linetype = expression(alpha)) +
theme_light() +
ggtitle(expression(paste(rho[m]," = 5.10-8"))) +
theme(
axis.title.x = element_text(size = 20),
axis.title.y = element_blank(),
legend.title = element_text(size = 20),
legend.text = element_text(size = 20),
axis.text.x = element_text(size = 17),
axis.text.y = element_blank(),
plot.title = element_text(size = 20, hjust = 0.5)) +
scale_y_continuous(limits = y_axis_limits)
library(ggplot2)
library(readr)
library(tibble)
library(dplyr)
library(sjPlot)
library(RColorBrewer)
library(cowplot)
rm(list=ls())
# Subset data for chr1
data_chr1 = read_csv('../data/pi_merged.csv') %>%
filter((h == 0.5 & s == 0.05) & (rho == '5e-08' | rho == '0,00000005')) %>%
mutate(alpha = as.factor(1 / GR)) %>%
mutate(ymin = mean - sd, ymax = mean + sd) %>%
filter(window != 'chr2') %>%
mutate(window = as.numeric(window) / 1000000)
data_chr1
# Subset data for chr2
data_chr2 = read_csv('../data/pi_merged.csv') %>%
filter(window == 'chr2') %>%
filter((h == 0.5 & s == 0.05) & (rho == '5e-08' | rho == '0,00000005')) %>%
mutate(alpha = as.factor(1 / GR)) %>%
mutate(ymin = mean - sd, ymax = mean + sd) %>%
mutate(label = case_when(rho == '5e-08' ~ 'rho', rho == '0,00000005' ~ 'rho_m', TRUE ~ 'other'))
data_chr2
# Explicitly set the y-axis limits to be the same for both plots
y_axis_limits <- c(-1e-5, 8e-05)
# Create color palette
num_conditions <- length(unique(data_chr1$alpha))
palette_name <- "Dark2"
colors <- brewer.pal(n = num_conditions, name = palette_name)
# Using the extracted color palette for both geom_line and geom_ribbon
plot_ctrl_chr1 = data_chr1 %>%
filter(rho == '5e-08') %>%
ggplot(aes(x = window, y = mean, group = alpha)) +
geom_ribbon(aes(ymin = ymin, ymax = ymax, fill = alpha), alpha = 0.2) +
geom_line(aes(color = alpha)) +
scale_color_manual(values = colors) +
scale_fill_manual(values = colors) +
labs(x = "Sequence position (Mbp)",
y = expression(pi ~ "along chromosome 1")) +
theme_light() +
ggtitle(expression(paste(rho, " = 5.10", " %*% ", 10^-8))) +
theme(
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
axis.text.x = element_text(size = 17),
axis.text.y = element_text(size = 18),
plot.title = element_text(size = 20, hjust = 0.5)
) +
guides(color = "none", fill = "none") +
scale_y_continuous(limits = y_axis_limits)
plot_ctrl_chr1
